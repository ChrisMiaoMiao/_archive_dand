{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析A/B测试结果\n",
    "\n",
    "这个项目可以帮你确认你已经掌握了统计课程中涵盖的所有内容。 希望这个项目尽可能地涵盖所有内容。 祝你好运！\n",
    "\n",
    "## 目录\n",
    "- [简介](#intro)\n",
    "- [I - 概率](#probability)\n",
    "- [II - A/B 测试](#ab_test)\n",
    "- [III - 回归](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### 简介\n",
    "\n",
    "通常情况下，A/B 测试由数据分析师和数据科学家来完成。如果你在一些实践工作中遇到过这方面的问题，那学习起来就会更加游刃有余。\n",
    "\n",
    "对于这个项目，你将要了解的是电子商务网站运行的 A/B 测试的结果。你的目标是通过这个 notebook 来帮助公司弄清楚他们是否应该使用新的页面，保留旧的页面，或者应该将测试时间延长，之后再做出决定。\n",
    "\n",
    "**使用该 notebook 的时候，请同步学习课堂内容，并回答与每个问题相关的对应测试题目。** 每个课堂概念的标签对应每个题目。这样可以确保你在完成项目的过程中的方法正确，并且你最终提交的内容会更加符合标准，不必担心出现错误。最后检查的时候，请确保你的提交内容符合 [审阅标准](https://review.udacity.com/#!/projects/37e27304-ad47-4eb0-a1ab-8c12f60e43d0/rubric) 中的所有标准。\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### I - 概率\n",
    "\n",
    "让我们先导入库，然后开始你的任务吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 现在，导入 `ab_data.csv` 数据，并将其存储在 `df` 中。  **使用你的 dataframe 来回答课堂测试 1 中的问题。**\n",
    "\n",
    "a. 导入数据集，并在这里查看前几行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id                   timestamp      group landing_page  converted\n",
      "0    851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
      "1    804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
      "2    661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
      "3    853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
      "4    864975  2017-01-21 01:52:26.210827    control     old_page          1\n",
      "5    936923  2017-01-10 15:20:49.083499    control     old_page          0\n",
      "6    679687  2017-01-19 03:26:46.940749  treatment     new_page          1\n",
      "7    719014  2017-01-17 01:48:29.539573    control     old_page          0\n",
      "8    817355  2017-01-04 17:58:08.979471  treatment     new_page          1\n",
      "9    839785  2017-01-15 18:11:06.610965  treatment     new_page          1\n",
      "10   929503  2017-01-18 05:37:11.527370  treatment     new_page          0\n",
      "11   834487  2017-01-21 22:37:47.774891  treatment     new_page          0\n",
      "12   803683  2017-01-09 06:05:16.222706  treatment     new_page          0\n",
      "13   944475  2017-01-22 01:31:09.573836  treatment     new_page          0\n",
      "14   718956  2017-01-22 11:45:11.327945  treatment     new_page          0\n",
      "15   644214  2017-01-22 02:05:21.719434    control     old_page          1\n",
      "16   847721  2017-01-17 14:01:00.090575    control     old_page          0\n",
      "17   888545  2017-01-08 06:37:26.332945  treatment     new_page          1\n",
      "18   650559  2017-01-24 11:55:51.084801    control     old_page          0\n",
      "19   935734  2017-01-17 20:33:37.428378    control     old_page          0\n",
      "20   740805  2017-01-12 18:59:45.453277  treatment     new_page          0\n",
      "21   759875  2017-01-09 16:11:58.806110  treatment     new_page          0\n",
      "22   767017  2017-01-12 22:58:14.991443    control     new_page          0\n",
      "23   793849  2017-01-23 22:36:10.742811  treatment     new_page          0\n",
      "24   905617  2017-01-20 14:12:19.345499  treatment     new_page          0\n",
      "25   746742  2017-01-23 11:38:29.592148    control     old_page          0\n",
      "26   892356  2017-01-05 09:35:14.904865  treatment     new_page          1\n",
      "27   773302  2017-01-12 08:29:49.810594  treatment     new_page          0\n",
      "28   913579  2017-01-24 09:11:39.164256    control     old_page          1\n",
      "29   736159  2017-01-06 01:50:21.318242  treatment     new_page          0\n",
      "30   690284  2017-01-13 17:22:57.182769    control     old_page          0\n",
      "31   826115  2017-01-05 11:27:16.756633  treatment     new_page          0\n",
      "32   875124  2017-01-05 15:39:25.439906  treatment     new_page          1\n",
      "33   931013  2017-01-07 03:23:57.932344  treatment     new_page          0\n",
      "34   710349  2017-01-11 22:24:44.226492    control     old_page          0\n",
      "35   677533  2017-01-23 17:48:50.491821    control     old_page          0\n",
      "36   831737  2017-01-11 21:18:20.911015    control     old_page          1\n",
      "37   648583  2017-01-19 09:03:05.545308  treatment     new_page          0\n",
      "38   728086  2017-01-03 17:07:00.837852  treatment     new_page          0\n",
      "39   870163  2017-01-02 21:33:49.325594  treatment     new_page          0\n",
      "40   771087  2017-01-16 00:05:29.983919    control     old_page          0\n",
      "41   739414  2017-01-03 13:25:55.139705  treatment     new_page          0\n",
      "42   896163  2017-01-22 09:10:20.753218    control     old_page          0\n",
      "43   862225  2017-01-08 14:49:37.335432    control     old_page          1\n",
      "44   939593  2017-01-05 09:15:31.984283    control     old_page          0\n",
      "45   702260  2017-01-18 13:55:31.488221    control     old_page          0\n",
      "46   943635  2017-01-22 13:37:39.722775  treatment     new_page          0\n",
      "47   800436  2017-01-20 07:47:47.224386  treatment     new_page          0\n",
      "48   698590  2017-01-23 11:51:59.925413  treatment     new_page          0\n",
      "49   830513  2017-01-12 00:50:01.470557  treatment     new_page          0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 使用下面的单元格来查找数据集中的行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 下面的用一种就行了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294478\n",
      "user_id         294478\n",
      "timestamp       294478\n",
      "group           294478\n",
      "landing_page    294478\n",
      "converted       294478\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df.count())\n",
    "df.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 数据集中独立用户的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 下面的是看所有列的独立值\n",
    "### 但是如果按照提问只看用户数量的话，可以怎么写呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         290584\n",
       "timestamp       294478\n",
       "group                2\n",
       "landing_page         2\n",
       "converted            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 用户转化的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 下面是按照 converted 是0或者1的，所以取sum再除以总数就是转化率\n",
    "### 这是一种简便算法，但如果是converted 的值是 yes 或者 no的话就不适用了\n",
    "### 这里可以改成一种更通用的方法，满足条件的筛选出来 再除以总数\n",
    "### 自己试一试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12126269856564711"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['converted'].sum() / df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.  `new_page` 与 `treatment` 不一致的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['landing_page']=='new_page')&(df['group']!='treatment')].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "f. 是否有任何行存在缺失值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 对于 **treatment** 不与 **new_page** 一致的行或 **control** 不与 **old_page** 一致的行，我们不能确定该行是否真正接收到了新的或旧的页面。我们应该如何处理这些行？在课堂中的 **测试 2** 中，给出你的答案。  \n",
    "\n",
    "a. 现在，使用测试题的答案创建一个符合测试规格要求的新数据集。将新 dataframe 存储在 **df2** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 下面的我直接标示在代码中了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290585"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dismatch_control = df[(df['landing_page']!='new_page')&(df['group']=='treatment')]\n",
    "# dismatch_control.shape[0]\n",
    "### 上面这行被注释掉的不需要，是过程数据。\n",
    "\n",
    "dismatch_treatment = df[(df['landing_page']=='new_page')&(df['group']!='treatment')]\n",
    "# dismatch_treatment.shape[0]\n",
    "### 上面这行被注释掉的不需要，是过程数据。\n",
    "\n",
    "\n",
    "### 下面从dismatch_sum 的命名看是吧上面两个求和\n",
    "### 但是代码呢却是求的一个比率，可以考虑改变代码的变量名字\n",
    "dismatch_sum = (dismatch_treatment.shape[0] + dismatch_treatment.shape[0]) / df.shape[0]\n",
    "# dismatch_sum\n",
    "### 上面这行被注释掉的不需要，是过程数据。\n",
    "\n",
    "match = df[(df['landing_page']=='new_page')&(df['group']=='treatment')].shape[0]\n",
    "dismatch_sum2= (dismatch_treatment.shape[0] + dismatch_control.shape[0]) / match\n",
    "dismatch_sum2\n",
    "\n",
    "### ！！！！ 这以上的行都删除，，，这里是把符合要求的生成一个df2\n",
    "### 下面代码已经完成任务了，和上面的没有关系！！！\n",
    "\n",
    "df2 = df[((df['landing_page']=='new_page')&(df['group']=='treatment'))|((df['landing_page']=='old_page')&(df['group']=='control'))]\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` 使用 **df2** 与下面的单元格来回答课堂中的 **测试3** 。\n",
    "\n",
    "a.  **df2** 中有多少唯一的 **user_id**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  **df2** 中有一个重复的 **user_id** 。它是什么？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 此处的问题是只显示user_id就行了，下一问是详细信息\n",
    "### 想想看怎么只显示出user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 这个重复的  **user_id** 的行信息是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 删除 **一个** 含有重复的 **user_id** 的行， 但需要确保你的 dataframe 为 **df2**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop_duplicates(['user_id'])\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 在下面的单元格中，使用 **df2** 来回答与课堂中的 **测试 4** 相关的测试题目。\n",
    "\n",
    "a. 不管它们收到什么页面，单个用户的转化率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_rate = df2['converted'].sum() / df2.shape[0]\n",
    "round(converted_rate, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 假定一个用户处于 `control` 组中，他的转化率是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 此处的分母要改一下，应该是所有control的个数\n",
    "# 因为是比较control转化率么，现在直接df2.shape[0]的话是所有数据\n",
    "# 包括了control和treatment的，所以数就不对了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060199999999999997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_converted_rate = df2[df2['group'] == 'control']['converted'].sum()/df2.shape[0]\n",
    "round(con_converted_rate , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 假定一个用户处于 `treatment` 组中，他的转化率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 同上一个修改建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059400000000000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tre_converted_rate = df2[df2['group'] == 'treatment']['converted'].sum()/df2.shape[0]\n",
    "round(tre_converted_rate , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 一个用户收到新页面的概率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpage_pro = df2[df2['landing_page'] == 'new_page'].shape[0] / df2.shape[0]\n",
    "round(newpage_pro,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 使用这个问题的前两部分的结果，给出你的建议：你是否认为有证据表明一个页面可以带来更多的转化？在下面写出你的答案。\n",
    "\n",
    "**在这里写出你的答案。**\n",
    "\n",
    "control组和treatment组的转化率差别不大，没有足够的证据表明一个页面可以带来更多的转化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### II - A/B 测试\n",
    "\n",
    "请注意，由于与每个事件相关的时间戳，你可以在进行每次观察时连续运行假设检验。  \n",
    "\n",
    "然而，问题的难点在于，一个页面被认为比另一页页面的效果好得多的时候你就要停止检验吗？还是需要在一定时间内持续发生？你需要将检验运行多长时间来决定哪个页面比另一个页面更好？\n",
    "\n",
    "一般情况下，这些问题是A / B测试中最难的部分。如果你对下面提到的一些知识点比较生疏，请先回顾课程中的“描述统计学”部分的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 现在，你要考虑的是，你需要根据提供的所有数据做出决定。如果你想假定旧的页面效果更好，除非新的页面在类型I错误率为5％的情况下才能证明效果更好，那么，你的零假设和备择假设是什么？ 你可以根据单词或旧页面与新页面的转化率 **$p_{old}$** 与 **$p_{new}$** 来陈述你的假设。\n",
    "\n",
    "**在这里给出你的答案。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$ H_0:p_{new}−p_{old}\\geq0 $\n",
    "\n",
    "$ H_1:p_{new}−p_{old} <0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 假定在零假设中，不管是新页面还是旧页面， $p_{new}$ and $p_{old}$ 都具有等于 **转化** 成功率的“真”成功率，也就是说，  $p_{new}$ 与 $p_{old}$ 是相等的。此外，假设它们都等于**ab_data.csv** 中的 **转化** 率，新旧页面都是如此。  <br><br>\n",
    "\n",
    "每个页面的样本大小要与 **ab_data.csv** 中的页面大小相同。  <br><br>\n",
    "\n",
    "执行两次页面之间 **转化** 差异的抽样分布，计算零假设中10000次迭代计算的估计值。  <br><br>\n",
    "\n",
    "使用下面的单元格提供这个模拟的必要内容。如果现在还没有完整的意义，不要担心，你将通过下面的问题来解决这个问题。你可以通过做课堂中的 **测试 5** 来确认你掌握了这部分内容。<br><br>\n",
    "\n",
    "a. 在零假设中，$p_{new}$ 的 **convert rate（转化率）** 是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = df2.converted.mean()\n",
    "round(p_new, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 在零假设中， $p_{old}$  的 **convert rate（转化率）** 是多少？ <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_old= df2.converted.mean()\n",
    "round(p_old, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.  $n_{new}$ 是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new=df2[df2['landing_page'] == 'new_page'].shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.  $n_{old}$?是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old=df2[df2['landing_page'] == 'old_page'].shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 在零假设中，使用 $p_{new}$ 转化率模拟 $n_{new}$ 交易，并将这些 $n_{new}$ 1's 与 0's 存储在 **new_page_converted** 中。(提示：可以使用  [numpy.random.choice](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html)。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.119049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted = np.random.choice([0, 1],n_new, p = [1-p_new,p_new])\n",
    "type(new_page_converted)\n",
    "new_page_conp= round(new_page_converted.mean(),6)\n",
    "new_page_conp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. 在零假设中，使用 $p_{old}$ 转化率模拟 $n_{old}$ 交易，并将这些  $n_{old}$ 1's 与 0's 存储在 **old_page_converted** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.120792"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted = np.random.choice([0, 1],n_old, p = [1-p_old,p_old])\n",
    "old_page_conp = round(old_page_converted.mean(),6)\n",
    "old_page_conp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. 在 (e) 与 (f)中找到 $p_{new}$ - $p_{old}$ 模拟值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0017429999999999946"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_compare = new_page_conp - old_page_conp\n",
    "p_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. 使用**a. 到 g. ** 中的计算方法来模拟 10,000个 $p_{new}$ - $p_{old}$ 值，并将这 10,000 个值存储在 **p_diffs** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = []\n",
    "for i in range(10000):\n",
    "    new_page_converted = np.random.choice([0,1],n_new, p = [1-p_new,p_new])\n",
    "    old_page_converted = np.random.choice([0,1],n_old, p = [1-p_old,p_old])\n",
    "    p_diffs.append(new_page_converted.mean()-old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. 绘制一个 **p_diffs** 直方图。这个直方图看起来像你所期望的吗？通过回答课堂上的匹配问题，确保你完全理解这里计算出的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAElBJREFUeJzt3X+s3fV93/HnqyYh25IWUwzzbGummScV/ihJrwhT9gcrHRioYiotqpGWWGkkVxpoidZpcpo/qNJFIu1aumgplVusmi2ty/JDsRJ31GWpokpLwFBCMC7jBtxwYw+7NSWpIlGZvvfH+Tg5tu+Pc3+cey58ng/pq/M97+/n+/1+vh9b93W/P865qSokSf35oUl3QJI0GQaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVOXTLoD87niiitq69atk+6GJL2uPP74439VVRsWardgACR5C/AV4NLW/jNVdU+Sq4EDwOXAE8D7qurvklwKPAj8JPDXwM9V1fG2rY8AHwReA/59VT083763bt3KkSNHFuqiJGlIkr8cpd0ol4BeBX6qqn4CuA7YnuQG4BPAfVW1DXiZwQ922uvLVfXPgPtaO5JcA+wErgW2A7+VZN3ohyRJWkkLBkAN/G17+6Y2FfBTwGdafT9wR5vf0d7Tlt+UJK1+oKperaoXgGng+hU5CknSoo10EzjJuiRPAqeAw8A3gb+pqrOtyQywqc1vAl4EaMtfAX50uD7LOpKkVTZSAFTVa1V1HbCZwW/tPz5bs/aaOZbNVT9Pkt1JjiQ5cvr06VG6J0lagkU9BlpVfwP8KXADcFmSczeRNwMn2vwMsAWgLf8R4MxwfZZ1hvext6qmqmpqw4YFb2JLkpZowQBIsiHJZW3+HwA/DRwDvgz8m9ZsF/CFNn+wvact/981+KszB4GdSS5tTxBtAx5dqQORJC3OKJ8D2Ajsb0/s/BDwUFV9MckzwIEk/xn4c+CB1v4B4L8nmWbwm/9OgKo6muQh4BngLHBXVb22socjSRpV1vKfhJyamio/ByBJi5Pk8aqaWqidXwUhSZ1a018FIa1lW/d8aSL7PX7v7RPZr954PAOQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn/KPwel2b1B9ml94IPAOQpE4ZAJLUKQNAkjq1YAAk2ZLky0mOJTma5EOt/stJvp3kyTbdNrTOR5JMJ3k2yS1D9e2tNp1kz3gOSZI0ilFuAp8FfrGqnkjyNuDxJIfbsvuq6r8MN05yDbATuBb4J8CfJPnnbfGngH8NzACPJTlYVc+sxIFIkhZnwQCoqpPAyTb/3STHgE3zrLIDOFBVrwIvJJkGrm/LpqvqeYAkB1pbA0CSJmBR9wCSbAXeAXytle5O8lSSfUnWt9om4MWh1WZaba66JGkCRg6AJG8FPgt8uKq+A9wPvB24jsEZwq+fazrL6jVP/cL97E5yJMmR06dPj9o9SdIijRQASd7E4If/p6vqcwBV9VJVvVZVfw/8Dj+4zDMDbBlafTNwYp76eapqb1VNVdXUhg0bFns8kqQRjfIUUIAHgGNV9RtD9Y1DzX4WeLrNHwR2Jrk0ydXANuBR4DFgW5Krk7yZwY3igytzGJKkxRrlKaB3A+8DvpHkyVb7JeDOJNcxuIxzHPgFgKo6muQhBjd3zwJ3VdVrAEnuBh4G1gH7quroCh6LJGkRRnkK6M+Y/fr9oXnW+Tjw8Vnqh+ZbT5K0evwksCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqQUDIMmWJF9OcizJ0SQfavXLkxxO8lx7Xd/qSfLJJNNJnkryzqFt7Wrtn0uya3yHJUlayChnAGeBX6yqHwduAO5Kcg2wB3ikqrYBj7T3ALcC29q0G7gfBoEB3AO8C7geuOdcaEiSVt+CAVBVJ6vqiTb/XeAYsAnYAexvzfYDd7T5HcCDNfBV4LIkG4FbgMNVdaaqXgYOA9tX9GgkSSNb1D2AJFuBdwBfA66qqpMwCAngytZsE/Di0GozrTZXXZI0ASMHQJK3Ap8FPlxV35mv6Sy1mqd+4X52JzmS5Mjp06dH7Z4kaZFGCoAkb2Lww//TVfW5Vn6pXdqhvZ5q9Rlgy9Dqm4ET89TPU1V7q2qqqqY2bNiwmGORJC3CKE8BBXgAOFZVvzG06CBw7kmeXcAXhurvb08D3QC80i4RPQzcnGR9u/l7c6tJkibgkhHavBt4H/CNJE+22i8B9wIPJfkg8C3gvW3ZIeA2YBr4HvABgKo6k+RXgMdau49V1ZkVOQpJ0qItGABV9WfMfv0e4KZZ2hdw1xzb2gfsW0wHJUnj4SeBJalTo1wCkrSGbN3zpYnt+/i9t09s31p5ngFIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcWDIAk+5KcSvL0UO2Xk3w7yZNtum1o2UeSTCd5NsktQ/XtrTadZM/KH4okaTFGOQP4PWD7LPX7quq6Nh0CSHINsBO4tq3zW0nWJVkHfAq4FbgGuLO1lSRNyCULNaiqryTZOuL2dgAHqupV4IUk08D1bdl0VT0PkORAa/vMonssSVoRy7kHcHeSp9olovWttgl4cajNTKvNVb9Ikt1JjiQ5cvr06WV0T5I0n6UGwP3A24HrgJPAr7d6Zmlb89QvLlbtraqpqprasGHDErsnSVrIgpeAZlNVL52bT/I7wBfb2xlgy1DTzcCJNj9XXZI0AUs6A0iycejtzwLnnhA6COxMcmmSq4FtwKPAY8C2JFcneTODG8UHl95tSdJyLXgGkOQPgBuBK5LMAPcANya5jsFlnOPALwBU1dEkDzG4uXsWuKuqXmvbuRt4GFgH7Kuqoyt+NJKkkY3yFNCds5QfmKf9x4GPz1I/BBxaVO8kSWPjJ4ElqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp5b0SWDpQlv3fGnSXZC0SJ4BSFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ1aMACS7EtyKsnTQ7XLkxxO8lx7Xd/qSfLJJNNJnkryzqF1drX2zyXZNZ7DkSSNapQzgN8Dtl9Q2wM8UlXbgEfae4BbgW1t2g3cD4PAAO4B3gVcD9xzLjQkSZOxYABU1VeAMxeUdwD72/x+4I6h+oM18FXgsiQbgVuAw1V1pqpeBg5zcahIklbRUu8BXFVVJwHa65Wtvgl4cajdTKvNVZckTchK3wTOLLWap37xBpLdSY4kOXL69OkV7Zwk6QeWGgAvtUs7tNdTrT4DbBlqtxk4MU/9IlW1t6qmqmpqw4YNS+yeJGkhSw2Ag8C5J3l2AV8Yqr+/PQ10A/BKu0T0MHBzkvXt5u/NrSZJmpBLFmqQ5A+AG4ErkswweJrnXuChJB8EvgW8tzU/BNwGTAPfAz4AUFVnkvwK8Fhr97GquvDGsiRpFS0YAFV15xyLbpqlbQF3zbGdfcC+RfVOkjQ2fhJYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdWvCPwkvSOVv3fGki+z1+7+0T2e8bnWcAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVPLCoAkx5N8I8mTSY602uVJDid5rr2ub/Uk+WSS6SRPJXnnShyAJGlpVuIM4F9V1XVVNdXe7wEeqaptwCPtPcCtwLY27QbuX4F9S5KWaByXgHYA+9v8fuCOofqDNfBV4LIkG8ewf0nSCJYbAAX8cZLHk+xutauq6iRAe72y1TcBLw6tO9Nq50myO8mRJEdOnz69zO5Jkuay3K+CeHdVnUhyJXA4yV/M0zaz1OqiQtVeYC/A1NTURcslSStjWWcAVXWivZ4CPg9cD7x07tJOez3Vms8AW4ZW3wycWM7+JUlLt+QASPKPkrzt3DxwM/A0cBDY1ZrtAr7Q5g8C729PA90AvHLuUpEkafUt5xLQVcDnk5zbzu9X1f9K8hjwUJIPAt8C3tvaHwJuA6aB7wEfWMa+JUnLtOQAqKrngZ+Ypf7XwE2z1Au4a6n7kyStLD8JLEmdMgAkqVMGgCR1ygCQpE4ZAJLUKf8o/BvMpP5ot6TXH88AJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOuW3gUpa8yb5LbfH7719YvseN88AJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqdW/THQJNuB/wqsA363qu5d7T6Mm3+YXdLrwaqeASRZB3wKuBW4BrgzyTWr2QdJ0sBqnwFcD0xX1fMASQ4AO4BnVrkfkjSSSZ3Rr8YH0FY7ADYBLw69nwHeNa6deSlGkua22gGQWWp1XoNkN7C7vf3bJM+OvVfLdwXwV5PuxBrgOAw4DgOOw8CSxiGfWNY+/+kojVY7AGaALUPvNwMnhhtU1V5g72p2armSHKmqqUn3Y9IchwHHYcBxGFjL47Daj4E+BmxLcnWSNwM7gYOr3AdJEqt8BlBVZ5PcDTzM4DHQfVV1dDX7IEkaWPXPAVTVIeDQau93zF5Xl6zGyHEYcBwGHIeBNTsOqaqFW0mS3nD8KghJ6pQBMI8klyc5nOS59rp+jna7Wpvnkuwaqv9kkm8kmU7yySS5YL3/mKSSXDHuY1mOcY1Dkl9L8hdJnkry+SSXrdYxLUaS7Umebf3fM8vyS5P8YVv+tSRbh5Z9pNWfTXLLqNtci1Z6HJJsSfLlJMeSHE3yodU7mqUbx/+Htmxdkj9P8sXxH0VTVU5zTMCvAnva/B7gE7O0uRx4vr2ub/Pr27JHgX/B4PMPfwTcOrTeFgY3w/8SuGLSxzqJcQBuBi5p85+YbbuTnhg8rPBN4MeANwNfB665oM2/A367ze8E/rDNX9PaXwpc3bazbpRtrrVpTOOwEXhna/M24P/2OA5D6/0H4PeBL67W8XgGML8dwP42vx+4Y5Y2twCHq+pMVb0MHAa2J9kI/HBV/Z8a/Os+eMH69wH/iQs+CLdGjWUcquqPq+psW/+rDD4XstZ8/+tLqurvgHNfXzJseHw+A9zUznJ2AAeq6tWqegGYbtsbZZtrzYqPQ1WdrKonAKrqu8AxBt8WsJaN4/8DSTYDtwO/uwrH8H0GwPyuqqqTAO31ylnazPb1FpvaNDNLnSTvAb5dVV8fR6fHYCzjcIGfZ3B2sNbMdVyztmmB9grwo/OsO8o215pxjMP3tcsk7wC+toJ9HodxjcNvMviF8O9XvstzW/XHQNeaJH8C/ONZFn101E3MUqu56kn+Ydv2zSNuf1Ws9jhcsO+PAmeBT4+4r9W0YP/naTNXfbZfvNb6meA4xmGwUvJW4LPAh6vqO0vu4epY8XFI8jPAqap6PMmNy+zfonQfAFX103MtS/JSko1VdbJdyjg1S7MZ4Mah95uBP231zRfUTwBvZ3D97+vtXuhm4Ikk11fV/1vGoSzLBMbh3LZ3AT8D3NQuEa01C359yVCbmSSXAD8CnFlg3YW2udaMZRySvInBD/9PV9XnxtP1FTWOcXgP8J4ktwFvAX44yf+oqn87nkMYMumbKmt5An6N829+/uosbS4HXmBw43N9m7+8LXsMuIEf3Py8bZb1j7P2bwKPZRyA7Qy+CnzDpI9xnmO/hMEN7av5wU2/ay9ocxfn3/R7qM1fy/k3/Z5ncBNxwW2utWlM4xAG94R+c9LHN8lxuGDdG1nFm8ATH9C1PDG4bvcI8Fx7PfcDbYrBXzM71+7nGdzQmQY+MFSfAp5mcLf/v9E+eHfBPl4PATCWcWjtXgSebNNvT/pY5zj+2xg8ofJN4KOt9jHgPW3+LcD/bMfzKPBjQ+t+tK33LOc/BXbRNtf6tNLjAPxLBpdGnhr6P3DRL0lrbRrH/4eh5asaAH4SWJI65VNAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE79fzL5kAfGqWmUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f112ae57ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j.  在**p_diffs**列表的数值中，有多大比例大于 **ab_data.csv** 中观察到的实际差值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 下面的代码是用了 \\ 将长代码拆分了\n",
    "### 试试使用几个变量，用比较短的代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90920000000000001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_diffs = \\\n",
    "df2.query('landing_page == \"new_page\"')['converted'].mean()- \\\n",
    "df2.query('landing_page == \"old_page\"')['converted'].mean()\n",
    "(p_diffs > obs_diffs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. 用文字解释一下你刚才在 **j.**中计算出来的结果。在科学研究中，这个值是什么？ 根据这个数值，新旧页面的转化率是否有区别呢？\n",
    "\n",
    "**在科学研究中，这个值是p值。P=0.9056 < 0.95无法否认零假设，因此认为新页面的转化率高于旧页面。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. 我们也可以使用一个内置程序 （built-in）来实现类似的结果。尽管使用内置程序可能更易于编写代码，但上面的内容是对正确思考统计显著性至关重要的思想的一个预排。填写下面的内容来计算每个页面的转化次数，以及每个页面的访问人数。使用 `n_old` 与 `n_new` 分别引证与旧页面和新页面关联的行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert = df2.query('converted ==\"1\"')\n",
    "converted_old = convert.query('landing_page == \"old_page\"').shape[0]\n",
    "converted_new = convert.query('landing_page == \"new_page\"').shape[0]\n",
    "n_old = n_old = df2.query('landing_page == \"old_page\"').shape[0]\n",
    "n_new = n_new = df2.query('landing_page == \"new_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. 现在使用 `stats.proportions_ztest` 来计算你的检验统计量与 p-值。[这里](http://knowledgetack.com/python/statsmodels/proportions_ztest/) 是使用内置程序的一个有用链接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.90505831275902449)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([converted_old,converted_new], [n_old, n_new], alternative='smaller')\n",
    "z_score,p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. 根据上题算出的 z-score 和 p-value，我们认为新旧页面的转化率是否有区别？它们与 **j.** 与 **k.** 中的结果一致吗？\n",
    "\n",
    "**检查z表格，在α= 0.05 时的值是1.96，所以1.31无法否认零假设；p值为0.905无法否认0假设，因此根据z-score和p-value，新页面的转化率高于旧页面的转化率，他们与JK中的结果一致。**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### III - 回归分析法之一\n",
    "\n",
    "`1.` 在最后一部分中，你会看到，你在之前的A / B测试中获得的结果也可以通过执行回归来获取。<br><br>\n",
    "\n",
    "a. 既然每行的值是转化或不转化，那么在这种情况下，我们应该执行哪种类型的回归？\n",
    "\n",
    "**逻辑回归**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 目标是使用 **statsmodels** 来拟合你在 **a.** 中指定的回归模型，以查看用户收到的不同页面是否存在显著的转化差异。但是，首先，你需要为这个截距创建一个列（ 原文：column） ，并为每个用户收到的页面创建一个虚拟变量列。添加一个 **截距** 列，一个 **ab_page** 列，当用户接收 **treatment** 时为1， **control** 时为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['intercept'] = 1\n",
    "df2[['new_page','old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "df2['ab_page'] = df['group'].map(lambda x: '1' if x==\"treatment\" else \"0\")\n",
    "df2['ab_page'] = df2['ab_page'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "c. 使用 **statsmodels** 导入你的回归模型。 实例化该模型，并使用你在 **b.** 中创建的2个列来拟合该模型，用来预测一个用户是否会发生转化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2['converted'],df2[['intercept','ab_page']])\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 请在下方提供你的模型摘要，并根据需要使用它来回答下面的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 21 Sep 2018</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:45:21</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Fri, 21 Sep 2018   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        19:45:21   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 此问中的假设与开始不同了！\n",
    "# 这个不可以的，因为一个项目就是要判断一个假设是否成立。\n",
    "# 这里是说这里的结果对假设的判断是什么样的，需要修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 与 **ab_page** 关联的 p-值是多少？ 为什么它与你在 **II** 中发现的结果不同？<br><br>  **提示**: 与你的回归模型相关的零假设与备择假设分别是什么？它们如何与 **Part II** 中的零假设和备择假设做比较？\n",
    "\n",
    "**ab_page的p_value是0.190。**\n",
    "\n",
    "**在回归模型中零假设和备择假设分别为**\n",
    "\n",
    "**$ H_0:p_{new}−p_{old}=0 $**\n",
    "\n",
    "**$ H_1:p_{new}−p_{old}\\neq0 $**\n",
    "\n",
    "**回归模型中是双尾检验，而Part II部分是单尾检验，因此结果不同。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "f. 现在，你一定在考虑其他可能影响用户是否发生转化的因素。讨论为什么考虑将其他因素添加到回归模型中是一个不错的主意。在回归模型中添加附加项有什么弊端吗？\n",
    "\n",
    "**更多因素会带来更准确训练结果，所以将其他因素添加到回归模型中是一个不错的主意。\n",
    "考虑太多的因素会造成对样本很管用（解决欠拟合问题），但对新的数据就没那么适用了（产生过拟合问题）。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. 现在，除了测试不同页面的转化率是否会发生变化之外，还要根据用户居住的国家或地区添加一个 effect 项。你需要导入 **countries.csv** 数据集，并将数据集合并在适当的行上。 [这里](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) 是链接表格的文档。 \n",
    "\n",
    "这个国家项对转化有影响吗？不要忘记为这些国家的列创建虚拟变量—— **提示: 你将需要为这三个虚拟变量增加两列。** 提供统计输出，并书面回答这个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936923</td>\n",
       "      <td>2017-01-10 15:20:49.083499</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>679687</td>\n",
       "      <td>2017-01-19 03:26:46.940749</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>719014</td>\n",
       "      <td>2017-01-17 01:48:29.539573</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>817355</td>\n",
       "      <td>2017-01-04 17:58:08.979471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>839785</td>\n",
       "      <td>2017-01-15 18:11:06.610965</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>929503</td>\n",
       "      <td>2017-01-18 05:37:11.527370</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>834487</td>\n",
       "      <td>2017-01-21 22:37:47.774891</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>803683</td>\n",
       "      <td>2017-01-09 06:05:16.222706</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>944475</td>\n",
       "      <td>2017-01-22 01:31:09.573836</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>718956</td>\n",
       "      <td>2017-01-22 11:45:11.327945</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>644214</td>\n",
       "      <td>2017-01-22 02:05:21.719434</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>847721</td>\n",
       "      <td>2017-01-17 14:01:00.090575</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>888545</td>\n",
       "      <td>2017-01-08 06:37:26.332945</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>650559</td>\n",
       "      <td>2017-01-24 11:55:51.084801</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>935734</td>\n",
       "      <td>2017-01-17 20:33:37.428378</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                   timestamp      group landing_page  converted  \\\n",
       "0    851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1    804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2    661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3    853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4    864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "5    936923  2017-01-10 15:20:49.083499    control     old_page          0   \n",
       "6    679687  2017-01-19 03:26:46.940749  treatment     new_page          1   \n",
       "7    719014  2017-01-17 01:48:29.539573    control     old_page          0   \n",
       "8    817355  2017-01-04 17:58:08.979471  treatment     new_page          1   \n",
       "9    839785  2017-01-15 18:11:06.610965  treatment     new_page          1   \n",
       "10   929503  2017-01-18 05:37:11.527370  treatment     new_page          0   \n",
       "11   834487  2017-01-21 22:37:47.774891  treatment     new_page          0   \n",
       "12   803683  2017-01-09 06:05:16.222706  treatment     new_page          0   \n",
       "13   944475  2017-01-22 01:31:09.573836  treatment     new_page          0   \n",
       "14   718956  2017-01-22 11:45:11.327945  treatment     new_page          0   \n",
       "15   644214  2017-01-22 02:05:21.719434    control     old_page          1   \n",
       "16   847721  2017-01-17 14:01:00.090575    control     old_page          0   \n",
       "17   888545  2017-01-08 06:37:26.332945  treatment     new_page          1   \n",
       "18   650559  2017-01-24 11:55:51.084801    control     old_page          0   \n",
       "19   935734  2017-01-17 20:33:37.428378    control     old_page          0   \n",
       "\n",
       "    intercept  new_page  old_page  ab_page country  \n",
       "0           1         0         1        0      US  \n",
       "1           1         0         1        0      US  \n",
       "2           1         1         0        1      US  \n",
       "3           1         1         0        1      US  \n",
       "4           1         0         1        0      US  \n",
       "5           1         0         1        0      US  \n",
       "6           1         1         0        1      CA  \n",
       "7           1         0         1        0      US  \n",
       "8           1         1         0        1      UK  \n",
       "9           1         1         0        1      CA  \n",
       "10          1         1         0        1      UK  \n",
       "11          1         1         0        1      US  \n",
       "12          1         1         0        1      US  \n",
       "13          1         1         0        1      US  \n",
       "14          1         1         0        1      US  \n",
       "15          1         0         1        0      US  \n",
       "16          1         0         1        0      US  \n",
       "17          1         1         0        1      US  \n",
       "18          1         0         1        0      CA  \n",
       "19          1         0         1        0      US  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('countries.csv')\n",
    "df2 = df2.join(df.set_index('user_id'), on='user_id')\n",
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['CA','UK','US']] = pd.get_dummies(df2['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 21 Sep 2018</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:45:22</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0375</td> <td>    0.026</td> <td>  -78.364</td> <td> 0.000</td> <td>   -2.088</td> <td>   -1.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0408</td> <td>    0.027</td> <td>    1.518</td> <td> 0.129</td> <td>   -0.012</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0507</td> <td>    0.028</td> <td>    1.786</td> <td> 0.074</td> <td>   -0.005</td> <td>    0.106</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Fri, 21 Sep 2018   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        19:45:22   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0375      0.026    -78.364      0.000      -2.088      -1.987\n",
       "US             0.0408      0.027      1.518      0.129      -0.012       0.093\n",
       "UK             0.0507      0.028      1.786      0.074      -0.005       0.106\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['intercept'] = 1\n",
    "lm = sm.Logit(df2['converted'],df2[['intercept','US','UK',]])\n",
    "result_country = lm.fit()\n",
    "result_country.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据两个虚拟列的p值，可以判断出转化率与国家没有显著相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. 虽然你现在已经查看了国家与页面在转化率上的个体性因素，但现在我们要查看页面与国家/地区之间的相互作用，测试其是否会对转化产生重大影响。创建必要的附加列，并拟合一个新的模型。  \n",
    "\n",
    "提供你的摘要结果，以及根据结果得出的结论。\n",
    "\n",
    "**提示：页面与国家/地区的相互作用**\n",
    "```\n",
    "df3['new_CA'] = df3['new_page'] * df3['CA']\n",
    "df3['new_UK'] = df3['new_page'] * df3['UK']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366117\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 21 Sep 2018</td> <th>  Pseudo R-squ.:     </th>  <td>1.082e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:45:23</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.3164</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9926</td> <td>    0.008</td> <td> -252.910</td> <td> 0.000</td> <td>   -2.008</td> <td>   -1.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_UK</th>    <td>    0.0112</td> <td>    0.018</td> <td>    0.626</td> <td> 0.532</td> <td>   -0.024</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_US</th>    <td>   -0.0144</td> <td>    0.012</td> <td>   -1.155</td> <td> 0.248</td> <td>   -0.039</td> <td>    0.010</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Fri, 21 Sep 2018   Pseudo R-squ.:               1.082e-05\n",
       "Time:                        19:45:23   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.3164\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9926      0.008   -252.910      0.000      -2.008      -1.977\n",
       "new_UK         0.0112      0.018      0.626      0.532      -0.024       0.046\n",
       "new_US        -0.0144      0.012     -1.155      0.248      -0.039       0.010\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2['new_US'] = df2['new_page'] * df2['US']\n",
    "df2['new_UK'] = df2['new_page'] * df2['UK']\n",
    "df2['intercept'] = 1\n",
    "lm = sm.Logit(df2['converted'],df2[['intercept','new_UK','new_US']])\n",
    "result_country = lm.fit()\n",
    "result_country.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据新增虚拟列的p值，可以判断出转化率和页面与国家/地区的相互作用没有显著相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## 总结\n",
    "\n",
    "祝贺你顺利完成了该项目！\n",
    "\n",
    "### 收集提交材料\n",
    "\n",
    "你对你的 notebook 的状态感到满意后，应该将其保存为便于其他人阅读并查看的格式。你可以使用 __File -> Download as -> HTML (.html)__ 菜单将你的 Notebook 保存为一个 .html 文件。如果你在本地操作，并发现了一个 \"找不到模块名称（No module name）\" 错误，请打开终端并尝试使用 `pip install <module_name>` 安装缺少的模块（注：在模块名称中，不要包含 \"<\" or \">\" 或任何带有期限的词汇）。\n",
    "\n",
    "你需要同时提交原始 Notebook 和 Notebook 的HTML或PDF副本以供审阅。你不需要在提交中附带任何数据文件。如果你参考了其他网站、书籍和其他资源来帮助你解决项目中的任务，请确保记录在案。建议你在 Notebook报告末尾的 Markdown 单元格中添加 “Resources” 部分，或者可以附带一个记录你的参考资源的 `readme.txt` 文件。\n",
    "\n",
    "### 提交项目\n",
    "\n",
    "准备就绪后，点击“提交项目”按钮进入项目提交页面。你可以将文件以 .zip压缩文件提交，也可以链接到包含项目文件的 GitHub 存储库。如果你使用的是 GitHub，请注意，你提交的内容将是提交时的链接库的一个快照。建议你将每个项目保存在一个单独的存储库中，以避免出现混淆：如果审阅专家获取多个文件夹来代表多个项目，则他可能不明确要评估哪个项目。\n",
    "\n",
    "我们需要一周的时间对项目进行评分，但在大多数情况下，速度要快得多。当你的提交被审阅后，你将会收到一封电子邮件。如果你在提交项目时遇到任何问题，或者想要查看提交状态，请发送电子邮件至 support@youdaxue.com。同时，你可以继续学习下一个单元的课程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
