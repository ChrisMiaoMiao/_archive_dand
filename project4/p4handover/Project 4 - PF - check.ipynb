{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析A/B测试结果\n",
    "\n",
    "这个项目可以帮你确认你已经掌握了统计课程中涵盖的所有内容。 希望这个项目尽可能地涵盖所有内容。 祝你好运！\n",
    "\n",
    "## 目录\n",
    "- [简介](#intro)\n",
    "- [I - 概率](#probability)\n",
    "- [II - A/B 测试](#ab_test)\n",
    "- [III - 回归](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### 简介\n",
    "\n",
    "通常情况下，A/B 测试由数据分析师和数据科学家来完成。如果你在一些实践工作中遇到过这方面的问题，那学习起来就会更加游刃有余。\n",
    "\n",
    "对于这个项目，你将要了解的是电子商务网站运行的 A/B 测试的结果。你的目标是通过这个 notebook 来帮助公司弄清楚他们是否应该使用新的页面，保留旧的页面，或者应该将测试时间延长，之后再做出决定。\n",
    "\n",
    "**使用该 notebook 的时候，请同步学习课堂内容，并回答与每个问题相关的对应测试题目。** 每个课堂概念的标签对应每个题目。这样可以确保你在完成项目的过程中的方法正确，并且你最终提交的内容会更加符合标准，不必担心出现错误。最后检查的时候，请确保你的提交内容符合 [审阅标准](https://review.udacity.com/#!/projects/37e27304-ad47-4eb0-a1ab-8c12f60e43d0/rubric) 中的所有标准。\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### I - 概率\n",
    "\n",
    "让我们先导入库，然后开始你的任务吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 现在，导入 `ab_data.csv` 数据，并将其存储在 `df` 中。  **使用你的 dataframe 来回答课堂测试 1 中的问题。**\n",
    "\n",
    "a. 导入数据集，并在这里查看前几行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                   timestamp      group landing_page  converted\n",
      "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
      "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
      "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
      "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
      "4   864975  2017-01-21 01:52:26.210827    control     old_page          1\n",
      "5   936923  2017-01-10 15:20:49.083499    control     old_page          0\n",
      "6   679687  2017-01-19 03:26:46.940749  treatment     new_page          1\n",
      "7   719014  2017-01-17 01:48:29.539573    control     old_page          0\n",
      "8   817355  2017-01-04 17:58:08.979471  treatment     new_page          1\n",
      "9   839785  2017-01-15 18:11:06.610965  treatment     new_page          1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 使用下面的单元格来查找数据集中的行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##1 这里两种方式用一个就可以了，比如\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 数据集中独立用户的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##2 此处要求是独立用户的数量，可以再精确点：\n",
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         290584\n",
       "timestamp       294478\n",
       "group                2\n",
       "landing_page         2\n",
       "converted            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 用户转化的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##3 这里可以换个方法，因为如果转换了 converted就是1，没有转化的话就是0\n",
    "# 所以直接对converted取平均数，就能得出转化率（这样处理更快）\n",
    "# 这里暂时可以不考虑用unique，因为题目没有引导（在实际中可以先处理好）\n",
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12126269856564711"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['converted'].sum() / df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.  `new_page` 与 `treatment` 不一致的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##4 这里只有new_page - control的数据，还缺control - treatment的数据\n",
    "# 这两个都加一起就全了\n",
    "# 这种筛选会比较慢，这里建议用groupby的方法，之后直接把groupby的运算出来就可以了\n",
    "match = df.groupby([\"group\", \"landing_page\"]).size()\n",
    "# 上面这句是说按照group和landing_page做分类，再计数（size（））\n",
    "match.loc['control'].loc['new_page'] + match.loc['treatment'].loc['old_page']\n",
    "# 直接把分组统计中两类不匹配的数加一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['landing_page']=='new_page')&(df['group']!='treatment')].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "f. 是否有任何行存在缺失值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 对于 **treatment** 不与 **new_page** 一致的行或 **control** 不与 **old_page** 一致的行，我们不能确定该行是否真正接收到了新的或旧的页面。我们应该如何处理这些行？在课堂中的 **测试 2** 中，给出你的答案。  \n",
    "\n",
    "a. 现在，使用测试题的答案创建一个符合测试规格要求的新数据集。将新 dataframe 存储在 **df2** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 plus 这里要在后面加个.copy()。这样的话df2和df是两份数据。如果不加后面会报警告\n",
    "# 不加的话对df2的修改也会体现到df上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[((df['landing_page']=='new_page')&(df['group']=='treatment'))|\n",
    "         ((df['landing_page']=='old_page')&(df['group']=='control'))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` 使用 **df2** 与下面的单元格来回答课堂中的 **测试3** 。\n",
    "\n",
    "a.  **df2** 中有多少唯一的 **user_id**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  **df2** 中有一个重复的 **user_id** 。它是什么？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###5 这里可以筛选出user_id这样和题目比较匹配（否则就和下一问相同了）\n",
    "df2[df2['user_id'].duplicated()]['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 这个重复的  **user_id** 的行信息是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 删除 **一个** 含有重复的 **user_id** 的行， 但需要确保你的 dataframe 为 **df2**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop_duplicates(['user_id'])\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 在下面的单元格中，使用 **df2** 来回答与课堂中的 **测试 4** 相关的测试题目。\n",
    "\n",
    "a. 不管它们收到什么页面，单个用户的转化率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_rate = df2['converted'].sum() / df2.shape[0]\n",
    "round(converted_rate, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 假定一个用户处于 `control` 组中，他的转化率是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1204"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_converted_rate = df2[df2['group'] == 'control']['converted'].sum()/df2[df2['group'] == 'control'].shape[0]\n",
    "round(con_converted_rate , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 假定一个用户处于 `treatment` 组中，他的转化率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1188"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tre_converted_rate = df2[df2['group'] == 'treatment']['converted'].sum()/df2[df2['group'] == 'treatment'].shape[0]\n",
    "round(tre_converted_rate , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 一个用户收到新页面的概率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpage_pro = df2[df2['landing_page'] == 'new_page'].shape[0] / df2.shape[0]\n",
    "round(newpage_pro,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "###6 下面说明‘一个页面’可以改成‘新的页面’，更准确些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 使用这个问题的前两部分的结果，给出你的建议：你是否认为有证据表明一个页面可以带来更多的转化？在下面写出你的答案。\n",
    "\n",
    "答案：  control组和treatment组的转化率差别不大，目前没有足够的证据表明一个页面可以带来更多的转化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### II - A/B 测试\n",
    "\n",
    "请注意，由于与每个事件相关的时间戳，你可以在进行每次观察时连续运行假设检验。  \n",
    "\n",
    "然而，问题的难点在于，一个页面被认为比另一页页面的效果好得多的时候你就要停止检验吗？还是需要在一定时间内持续发生？你需要将检验运行多长时间来决定哪个页面比另一个页面更好？\n",
    "\n",
    "一般情况下，这些问题是A / B测试中最难的部分。如果你对下面提到的一些知识点比较生疏，请先回顾课程中的“描述统计学”部分的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 现在，你要考虑的是，你需要根据提供的所有数据做出决定。如果你想假定旧的页面效果更好，除非新的页面在类型I错误率为5％的情况下才能证明效果更好，那么，你的零假设和备择假设是什么？ 你可以根据单词或旧页面与新页面的转化率 **$p_{old}$** 与 **$p_{new}$** 来陈述你的假设。\n",
    "\n",
    "**在这里给出你的答案。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答案："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\###7 导学是按照这个假设写的：零假设是新页面不比旧页面更好（我们想要推翻的），因为涉及到单位和双尾。这里也可以保留你的，内容是正确的。但是后面有些说明是要调整的（因为单双尾判断再大于和等于有不同）。这里是按照大于等于写的。可以考虑连假设一同修改。\n",
    "\n",
    "$ H_0:p_{new}−p_{old}\\leq0 $\n",
    "\n",
    "$ H_1:p_{new}−p_{old}>0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$ H_0:p_{new}−p_{old}=0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$ H_1:p_{new}−p_{old}\\neq0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 假定在零假设中，不管是新页面还是旧页面， $p_{new}$ and $p_{old}$ 都具有等于 **转化** 成功率的“真”成功率，也就是说，  $p_{new}$ 与 $p_{old}$ 是相等的。此外，假设它们都等于**ab_data.csv** 中的 **转化** 率，新旧页面都是如此。  <br><br>\n",
    "\n",
    "每个页面的样本大小要与 **ab_data.csv** 中的页面大小相同。  <br><br>\n",
    "\n",
    "执行两次页面之间 **转化** 差异的抽样分布，计算零假设中10000次迭代计算的估计值。  <br><br>\n",
    "\n",
    "使用下面的单元格提供这个模拟的必要内容。如果现在还没有完整的意义，不要担心，你将通过下面的问题来解决这个问题。你可以通过做课堂中的 **测试 5** 来确认你掌握了这部分内容。<br><br>\n",
    "\n",
    "a. 在零假设中，$p_{new}$ 的 **convert rate（转化率）** 是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = df2.converted.mean()\n",
    "round(p_new, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 在零假设中， $p_{old}$  的 **convert rate（转化率）** 是多少？ <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_old= df2.converted.mean()\n",
    "round(p_old, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.  $n_{new}$ 是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new=df2[df2['landing_page'] == 'new_page'].shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.  $n_{old}$?是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old=df2[df2['landing_page'] == 'old_page'].shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 在零假设中，使用 $p_{new}$ 转化率模拟 $n_{new}$ 交易，并将这些 $n_{new}$ 1's 与 0's 存储在 **new_page_converted** 中。(提示：可以使用  [numpy.random.choice](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html)。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.118856"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted = np.random.choice([0, 1],n_new, p = [1-p_new,p_new])\n",
    "type(new_page_converted)\n",
    "new_page_conp= round(new_page_converted.mean(),6)\n",
    "new_page_conp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. 在零假设中，使用 $p_{old}$ 转化率模拟 $n_{old}$ 交易，并将这些  $n_{old}$ 1's 与 0's 存储在 **old_page_converted** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.120572"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted = np.random.choice([0, 1],n_old, p = [1-p_old,p_old])\n",
    "old_page_conp = round(old_page_converted.mean(),6)\n",
    "old_page_conp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. 在 (e) 与 (f)中找到 $p_{new}$ - $p_{old}$ 模拟值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0017159999999999953"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_compare = new_page_conp - old_page_conp\n",
    "p_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. 使用**a. 到 g. ** 中的计算方法来模拟 10,000个 $p_{new}$ - $p_{old}$ 值，并将这 10,000 个值存储在 **p_diffs** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = []\n",
    "for i in range(1000):\n",
    "    new_page_converted = np.random.choice([0,1],n_new, p = [1-p_new,p_new])\n",
    "    old_page_converted = np.random.choice([0,1],n_old, p = [1-p_old,p_old])\n",
    "    p_diffs.append(new_page_converted.mean()-old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. 绘制一个 **p_diffs** 直方图。这个直方图看起来像你所期望的吗？通过回答课堂上的匹配问题，确保你完全理解这里计算出的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j.  在**p_diffs**列表的数值中，有多大比例大于 **ab_data.csv** 中观察到的实际差值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_diffs = df2.query('landing_page == \"new_page\"')['converted'].mean()- df2.query('landing_page == \"old_page\"')['converted'].mean()\n",
    "(p_diffs > obs_diffs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. 用文字解释一下你刚才在 **j.**中计算出来的结果。在科学研究中，这个值是什么？ 根据这个数值，新旧页面的转化率是否有区别呢？\n",
    "\n",
    "**在这里给出你的答案。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\###7 答案的最后一句需要修改（我加黑了）。不能否定零假设（参见新的），就是说零假设为真即：新页面的转换率并不比旧页面更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答案： 这个值就是p值。P=0.902 < 0.95，无法否认零假设，**因此认为新页面的转化率高于旧页面。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. 我们也可以使用一个内置程序 （built-in）来实现类似的结果。尽管使用内置程序可能更易于编写代码，但上面的内容是对正确思考统计显著性至关重要的思想的一个预排。填写下面的内容来计算每个页面的转化次数，以及每个页面的访问人数。使用 `n_old` 与 `n_new` 分别引证与旧页面和新页面关联的行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert = df2.query('converted ==\"1\"')\n",
    "converted_old = convert.query('landing_page == \"old_page\"').shape[0]\n",
    "converted_new = convert.query('landing_page == \"new_page\"').shape[0]\n",
    "n_old = n_old = df2.query('landing_page == \"old_page\"').shape[0]\n",
    "n_new = n_new = df2.query('landing_page == \"new_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. 现在使用 `stats.proportions_ztest` 来计算你的检验统计量与 p-值。[这里](http://knowledgetack.com/python/statsmodels/proportions_ztest/) 是使用内置程序的一个有用链接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([converted_old,converted_new], [n_old, n_new], alternative='smaller')\n",
    "z_score,p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. 根据上题算出的 z-score 和 p-value，我们认为新旧页面的转化率是否有区别？它们与 **j.** 与 **k.** 中的结果一致吗？\n",
    "\n",
    "答案： 检查z表格，当α= 0.05 时的值是1.96，所以1.31无法否认零假设；p值为0.905无法否认0假设，因此根据z-score和p-value，新页面的转化率高于旧页面的转化率，他们与J和K中的结果一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### III - 回归分析法之一\n",
    "\n",
    "`1.` 在最后一部分中，你会看到，你在之前的A / B测试中获得的结果也可以通过执行回归来获取。<br><br>\n",
    "\n",
    "a. 既然每行的值是转化或不转化，那么在这种情况下，我们应该执行哪种类型的回归？\n",
    "\n",
    "答案： 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 目标是使用 **statsmodels** 来拟合你在 **a.** 中指定的回归模型，以查看用户收到的不同页面是否存在显著的转化差异。但是，首先，你需要为这个截距创建一个列（ 原文：column） ，并为每个用户收到的页面创建一个虚拟变量列。添加一个 **截距** 列，一个 **ab_page** 列，当用户接收 **treatment** 时为1， **control** 时为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['intercept'] = 1\n",
    "df2[['new_page','old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "df2['ab_page'] = df['group'].map(lambda x: '1' if x==\"treatment\" else \"0\")\n",
    "df2['ab_page'] = df2['ab_page'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "c. 使用 **statsmodels** 导入你的回归模型。 实例化该模型，并使用你在 **b.** 中创建的2个列来拟合该模型，用来预测一个用户是否会发生转化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2['converted'],df2[['intercept','ab_page']])\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 请在下方提供你的模型摘要，并根据需要使用它来回答下面的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 10 Oct 2018</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:36:40</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Wed, 10 Oct 2018   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        00:36:40   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\### 8 这里既然判断出来是双尾假设（上面的结果是 P>|z| 大于小于都可以，所以是双尾）\n",
    "而且根据要求也要写出这部分的假设（这个项目隐含的是II部分和III部分是两个假设判断，所以可以有两个假设描述（我已经加上了）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 与 **ab_page** 关联的 p-值是多少？ 为什么它与你在 **II** 中发现的结果不同？<br><br>  **提示**: 与你的回归模型相关的零假设与备择假设分别是什么？它们如何与 **Part II** 中的零假设和备择假设做比较？\n",
    "\n",
    "答案： ab_page的p值是0.190。在PartII中的P值是单尾假设，而此处的回归模型中的P值是双尾假设，因此它与PartII的结果不同。\n",
    "\n",
    "这里的假设是：\n",
    "\n",
    "$ H_0:p_{new}−p_{old} = 0 $\n",
    "\n",
    "$ H_1:p_{new}−p_{old} \\neq0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "f. 现在，你一定在考虑其他可能影响用户是否发生转化的因素。讨论为什么考虑将其他因素添加到回归模型中是一个不错的主意。在回归模型中添加附加项有什么弊端吗？\n",
    "\n",
    "答案： 更多因素会带来更准确的训练结果，因此将其他的因素添加到回归模型中是一个不错的主意。 但是考虑到太多的因素会造成 对样本很管用（解决欠拟合问题），但对新的数据就没那么适用（产生过拟合问题）的状况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. 现在，除了测试不同页面的转化率是否会发生变化之外，还要根据用户居住的国家或地区添加一个 effect 项。你需要导入 **countries.csv** 数据集，并将数据集合并在适当的行上。 [这里](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) 是链接表格的文档。 \n",
    "\n",
    "这个国家项对转化有影响吗？不要忘记为这些国家的列创建虚拟变量—— **提示: 你将需要为这三个虚拟变量增加两列。** 提供统计输出，并书面回答这个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['country'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-0ee17e3a9694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 已经修改在这个代码框了（只能运行1遍，多次的话应为已经处理过了会报错，不用管）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'countries.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6334\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6336\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6349\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   6350\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6351\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   6352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                          validate=validate)\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 574\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   5242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m             raise ValueError('columns overlap but no suffix specified: '\n\u001b[0;32m-> 5244\u001b[0;31m                              '{rename}'.format(rename=to_rename))\n\u001b[0m\u001b[1;32m   5245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5246\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['country'], dtype='object')"
     ]
    }
   ],
   "source": [
    "### 9 这里代码中country应该是df，因为第一行已经把countries的内容读到了df中：\n",
    "# 已经修改在这个代码框了（只能运行1遍，多次的话应为已经处理过了会报错，不用管）\n",
    "df = pd.read_csv('countries.csv')\n",
    "df2 = df2.join(df.set_index('user_id'), on='user_id')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['CA','UK','US']] = pd.get_dummies(df2['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 10 Oct 2018</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:52:32</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0375</td> <td>    0.026</td> <td>  -78.364</td> <td> 0.000</td> <td>   -2.088</td> <td>   -1.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0408</td> <td>    0.027</td> <td>    1.518</td> <td> 0.129</td> <td>   -0.012</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0507</td> <td>    0.028</td> <td>    1.786</td> <td> 0.074</td> <td>   -0.005</td> <td>    0.106</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 10 Oct 2018   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        00:52:32   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0375      0.026    -78.364      0.000      -2.088      -1.987\n",
       "US             0.0408      0.027      1.518      0.129      -0.012       0.093\n",
       "UK             0.0507      0.028      1.786      0.074      -0.005       0.106\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['intercept'] = 1\n",
    "lm = sm.Logit(df2['converted'],df2[['intercept','US','UK',]])\n",
    "result_country = lm.fit()\n",
    "result_country.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. 虽然你现在已经查看了国家与页面在转化率上的个体性因素，但现在我们要查看页面与国家/地区之间的相互作用，测试其是否会对转化产生重大影响。创建必要的附加列，并拟合一个新的模型。  \n",
    "\n",
    "提供你的摘要结果，以及根据结果得出的结论。\n",
    "\n",
    "**提示：页面与国家/地区的相互作用**\n",
    "```\n",
    "df3['new_CA'] = df3['new_page'] * df3['CA']\n",
    "df3['new_UK'] = df3['new_page'] * df3['UK']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 10 Oct 2018</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:56:09</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0040</td> <td>    0.036</td> <td>  -55.008</td> <td> 0.000</td> <td>   -2.075</td> <td>   -1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0674</td> <td>    0.052</td> <td>   -1.297</td> <td> 0.195</td> <td>   -0.169</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0118</td> <td>    0.040</td> <td>    0.296</td> <td> 0.767</td> <td>   -0.066</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0175</td> <td>    0.038</td> <td>    0.465</td> <td> 0.642</td> <td>   -0.056</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_UK</th>    <td>    0.0783</td> <td>    0.057</td> <td>    1.378</td> <td> 0.168</td> <td>   -0.033</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_US</th>    <td>    0.0469</td> <td>    0.054</td> <td>    0.872</td> <td> 0.383</td> <td>   -0.059</td> <td>    0.152</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Wed, 10 Oct 2018   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        00:56:09   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1920\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0040      0.036    -55.008      0.000      -2.075      -1.933\n",
       "ab_page       -0.0674      0.052     -1.297      0.195      -0.169       0.034\n",
       "UK             0.0118      0.040      0.296      0.767      -0.066       0.090\n",
       "US             0.0175      0.038      0.465      0.642      -0.056       0.091\n",
       "new_UK         0.0783      0.057      1.378      0.168      -0.033       0.190\n",
       "new_US         0.0469      0.054      0.872      0.383      -0.059       0.152\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 10 这里之前的导学中有一点要更新\n",
    "# 因为new_US，new_UK这两列是复合列，所以这里还要把原始的US，UK和ab_page一起加到分析的变量中\n",
    "# 理解后清理，旧的代码做了标示\n",
    "df2['new_US'] = df2['new_page'] * df2['US']\n",
    "df2['new_UK'] = df2['new_page'] * df2['UK']\n",
    "df2['intercept'] = 1\n",
    "# lm = sm.Logit(df2['converted'],df2[['intercept','new_UK','new_US']])\n",
    "lm = sm.Logit(df2['converted'],df2[['intercept','ab_page','UK','US','new_UK','new_US']])\n",
    "result_country = lm.fit()\n",
    "result_country.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据新增虚拟列的p值，可以判断出转化率和页面与国家/地区的相互作用没有显著相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## 总结\n",
    "\n",
    "祝贺你顺利完成了该项目！\n",
    "\n",
    "### 收集提交材料\n",
    "\n",
    "你对你的 notebook 的状态感到满意后，应该将其保存为便于其他人阅读并查看的格式。你可以使用 __File -> Download as -> HTML (.html)__ 菜单将你的 Notebook 保存为一个 .html 文件。如果你在本地操作，并发现了一个 \"找不到模块名称（No module name）\" 错误，请打开终端并尝试使用 `pip install <module_name>` 安装缺少的模块（注：在模块名称中，不要包含 \"<\" or \">\" 或任何带有期限的词汇）。\n",
    "\n",
    "你需要同时提交原始 Notebook 和 Notebook 的HTML或PDF副本以供审阅。你不需要在提交中附带任何数据文件。如果你参考了其他网站、书籍和其他资源来帮助你解决项目中的任务，请确保记录在案。建议你在 Notebook报告末尾的 Markdown 单元格中添加 “Resources” 部分，或者可以附带一个记录你的参考资源的 `readme.txt` 文件。\n",
    "\n",
    "### 提交项目\n",
    "\n",
    "准备就绪后，点击“提交项目”按钮进入项目提交页面。你可以将文件以 .zip压缩文件提交，也可以链接到包含项目文件的 GitHub 存储库。如果你使用的是 GitHub，请注意，你提交的内容将是提交时的链接库的一个快照。建议你将每个项目保存在一个单独的存储库中，以避免出现混淆：如果审阅专家获取多个文件夹来代表多个项目，则他可能不明确要评估哪个项目。\n",
    "\n",
    "我们需要一周的时间对项目进行评分，但在大多数情况下，速度要快得多。当你的提交被审阅后，你将会收到一封电子邮件。如果你在提交项目时遇到任何问题，或者想要查看提交状态，请发送电子邮件至 support@youdaxue.com。同时，你可以继续学习下一个单元的课程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
